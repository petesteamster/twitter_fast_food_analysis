{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('./ready_for_cvec.csv', dtype=object, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33653, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = profiles.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23340, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     17538\n",
       "-1     5802\n",
       "Name: sentiment_dummies, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.sentiment_dummies.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested all of the profile 'clean' levels, i.e. with different components removed/included\n",
    "X = profiles.without_hashes\n",
    "y = profiles.sentiment_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.casual.TweetTokenizer(preserve_case=False, reduce_len=True,strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(tokenizer= tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cvec.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71966581, 0.71863753, 0.71940874])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(classifier, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1     1   All\n",
      "Actual                    \n",
      "-1         113  1342  1455\n",
      "1          260  4120  4380\n",
      "All        373  5462  5835 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#underpredicting negative sentiment from profiles\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "print(pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models against baseline\n",
    "## and logistic regression before hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic model testing function\n",
    "def model_tester(X, y, model, return_vals=False):\n",
    "    \"\"\"Prints basic classification matrix and accuracy for a given model\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                        stratify=profiles['sentiment_dummies'], test_size=0.3)\n",
    "    modeled = model()\n",
    "    modeled.fit(X_train, y_train)\n",
    "    predictions = modeled.predict(X_test)\n",
    "    print(pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True), '\\n')\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    if return_vals:\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     17538\n",
      "-1     5802\n",
      "Name: sentiment_dummies, dtype: int64 \n",
      "\n",
      "BASELINE\n",
      "0.7518423307626393\n"
     ]
    }
   ],
   "source": [
    "#Baseline- if I predict 1 everytime, I have 75% accuracy\n",
    "print(profiles['sentiment_dummies'].value_counts(), '\\n')\n",
    "print('BASELINE')\n",
    "print(17548/profiles.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1     1   All\n",
      "Actual                    \n",
      "-1         145  1596  1741\n",
      "1          331  4930  5261\n",
      "All        476  6526  7002 \n",
      "\n",
      "0.7247929163096258\n"
     ]
    }
   ],
   "source": [
    "model_tester(X, y, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1     1   All\n",
      "Actual                    \n",
      "-1         102  1639  1741\n",
      "1          262  4999  5261\n",
      "All        364  6638  7002 \n",
      "\n",
      "0.7285061411025421\n"
     ]
    }
   ],
   "source": [
    "model_tester(X, y, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    -1     1   All\n",
      "Actual                     \n",
      "-1          317  1424  1741\n",
      "1           850  4411  5261\n",
      "All        1167  5835  7002 \n",
      "\n",
      "0.675235646958012\n"
     ]
    }
   ],
   "source": [
    "model_tester(X, y, RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bern = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1.1, 1.2, 1.3, 1.9, 2.2, 2.4], 'fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'alpha': [ 1.1, 1.2, 1.3, 1.9, 2.2, 2.4], 'fit_prior':[True, False], \n",
    "             }\n",
    "clf = GridSearchCV(bern, param_grid=param_grid)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7491431019708654"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=2.4, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5835\n",
      "5705\n"
     ]
    }
   ],
   "source": [
    "print(len(clf.predict(X_test)))\n",
    "print(np.sum([int(x) for x in list(clf.predict(X_test))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now performing basic test with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer().fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = tfidf.transform(df)\n",
    "ss = StandardScaler()\n",
    "df_tfidf = ss.fit_transform(df_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1     1   All\n",
      "Actual                    \n",
      "-1         207  1537  1744\n",
      "1          566  4692  5258\n",
      "All        773  6229  7002 \n",
      "\n",
      "0.6996572407883462\n"
     ]
    }
   ],
   "source": [
    "#marginally better than just the countvectorizer \n",
    "model_tester(df_tfidf, y, MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incorporating additional profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slevin886/anaconda2/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/slevin886/anaconda2/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#if building this model just on profiles, without pulling a sample of the user's tweets, drop\n",
    "#weekday, hour\n",
    "df = profiles[['number_of_people_they_follow',\n",
    "          'number_of_user_tweets', 'user_followers_count', 'user_is_verified',\n",
    "          'weekday', 'hour', 'profile_length', 'percent_in_dictionary', 'number_of_hashes']]\n",
    "\n",
    "#converting datatypes\n",
    "\n",
    "for col in list(df.columns):\n",
    "    try: \n",
    "        df[col] = df[col].astype(int)\n",
    "    except:\n",
    "        df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing \n",
    "df_ss = pd.DataFrame(ss.fit_transform(df), columns=list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_merged = pd.concat([Z, df_ss], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    -1    1   All\n",
      "Actual                    \n",
      "-1         1440  203  1643\n",
      "1          4620  739  5359\n",
      "All        6060  942  7002 \n",
      "\n",
      "0.3111968009140246\n"
     ]
    }
   ],
   "source": [
    "model_tester(Z_merged, y, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58399678, 0.99342875, 0.99999961, 0.99999999, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformed = pca.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_headers = ['PC' + str(i) for i in range(1, 10)]\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=col_headers)\n",
    "df_transformed = df_transformed.drop(['PC' + str(i) for i in range(3, 10)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_merged = pd.concat([Z, df_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    -1     1   All\n",
      "Actual                     \n",
      "-1         1498   251  1749\n",
      "1          4503   750  5253\n",
      "All        6001  1001  7002 \n",
      "\n",
      "0.32105112824907167\n"
     ]
    }
   ],
   "source": [
    "model_tester(df, y, MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unused LSA dimensionality reduction below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOOKING AT LSA (truncatedSVD)\n",
    "\n",
    "# #Looked at reducing dimensionality, classifying positive more than 98% of time\n",
    "# lsa = TruncatedSVD(n_components=100)\n",
    "# lsa.fit(X)\n",
    "# X = lsa.transform(X)\n",
    "\n",
    "# #turning PCA into dataframe\n",
    "# cols = ['PCA' + str(i) for i in range(1, 101)]\n",
    "# df = pd.DataFrame(X, columns=cols)\n",
    "\n",
    "# #very high scores, but... see below\n",
    "# cross_val_score(classifier, df, y)\n",
    "\n",
    "# #Seeing what was happening- predicted almost entirely positive sentiments\n",
    "# lr = LogisticRegression()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df, y)\n",
    "# lr.fit(X_train, y_train)\n",
    "# predictions = lr.predict(X_test)\n",
    "# print(pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
