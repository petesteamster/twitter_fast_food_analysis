{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import feature_selection\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.read_csv('../complete_data_models.csv', dtype=object, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eliminating 20,000 null profiles\n",
    "full.drop(list(full[(full.user_profile_text.isnull())].index), axis=0, inplace=True)\n",
    "full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67658, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_neutrals = full.copy()\n",
    "no_neutrals = no_neutrals.loc[(no_neutrals.sentiment_dummies.isin(['1', '-1']))].reset_index(drop=True)\n",
    "no_neutrals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51500, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_neutrals.drop_duplicates(subset='user_name', inplace=True)\n",
    "no_neutrals.reset_index(drop=True, inplace=True)\n",
    "no_neutrals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:  0.7261553398058253\n"
     ]
    }
   ],
   "source": [
    "no_neutrals.sentiment_dummies.value_counts()\n",
    "print('Baseline: ',37397 / (37397 + 14103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#going to clean X \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.add('would') \n",
    "\n",
    "def cleaner(title):\n",
    "    \"\"\" This function accepts a string, tokenizes it, removes stopwords,\n",
    "    lemmatizes them, and then return the words as a joined string\"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = re.sub(r'(https)[^\\s]+', ' ', title)\n",
    "    text = re.sub(r'@[a-zA-Z0-9]+', ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    text = re.sub(r'\\b(rt|RT)', ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z]\", ' ', text)\n",
    "    profile = tokenizer.tokenize(text.lower())\n",
    "    lst = [word for word in profile if word not in stop]\n",
    "    lemons = [lemmatizer.lemmatize(word) for word in lst]\n",
    "    short_lemons = [word for word in lemons if len(word) > 2]\n",
    "    final = ' '.join(short_lemons)\n",
    "    return final\n",
    "\n",
    "no_neutrals['user_profile_text'] = no_neutrals.user_profile_text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = no_neutrals['user_profile_text']\n",
    "y = no_neutrals['sentiment_dummies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(min_df=2, ngram_range=(1, 2))\n",
    "cvec.fit(X)\n",
    "X = cvec.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.todense(), columns= cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(tfidf, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=1, score_func=<function chi2 at 0x10dc1a6a8>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=1)\n",
    "fs.fit(tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>bts</td>\n",
       "      <td>17.333113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>twt</td>\n",
       "      <td>12.552360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>directioner</td>\n",
       "      <td>8.898642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>fan account</td>\n",
       "      <td>8.459397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>colby</td>\n",
       "      <td>8.395904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>youngest</td>\n",
       "      <td>7.436030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>stupid</td>\n",
       "      <td>6.670543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>candle</td>\n",
       "      <td>6.621854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>badass</td>\n",
       "      <td>6.579720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>army</td>\n",
       "      <td>6.258173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>fine art</td>\n",
       "      <td>6.174547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>vagabond</td>\n",
       "      <td>6.156992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bap</td>\n",
       "      <td>5.982842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>voltron</td>\n",
       "      <td>5.746199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>nutella</td>\n",
       "      <td>5.517474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word      score\n",
       "65           bts  17.333113\n",
       "408          twt  12.552360\n",
       "114  directioner   8.898642\n",
       "148  fan account   8.459397\n",
       "90         colby   8.395904\n",
       "450     youngest   7.436030\n",
       "387       stupid   6.670543\n",
       "74        candle   6.621854\n",
       "34        badass   6.579720\n",
       "19          army   6.258173\n",
       "152     fine art   6.174547\n",
       "420     vagabond   6.156992\n",
       "36           bap   5.982842\n",
       "423      voltron   5.746199\n",
       "306      nutella   5.517474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_import = pd.DataFrame(index=X.columns[fs.get_support()], data=fs.scores_[fs.get_support()]).reset_index()\n",
    "word_import.columns = ['word' ,'score']\n",
    "word_import.sort_values(by='score', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=35, score_func=<function chi2 at 0x10dc1a6a8>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting feature importance based on whole dataset first, then will do on just training\n",
    "#testing with 35% most important features\n",
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=35)\n",
    "fs.fit(tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tf = pd.DataFrame(tfidf.toarray())\n",
    "df_tf.columns = cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_35 = df_tf[list(df_tf.columns[fs.get_support()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_35, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli- 35% most important features- with TFIDF\n",
      "Predicted    -1      1    All\n",
      "Actual                       \n",
      "-1          777   2749   3526\n",
      "1           593   8756   9349\n",
      "All        1370  11505  12875\n",
      "accuracy:  0.7404271844660194\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "print('Bernoulli- 35% most important features- with TFIDF')\n",
    "print(pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "print('accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#beat the BASELINE! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:35<00:00, 55.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#testing what percentage of features to keep\n",
    "results = []\n",
    "for i in tqdm(range(15, 40, 5)):\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=i)\n",
    "    fs.fit(tfidf, y)\n",
    "    X = df_tf[list(df_tf.columns[fs.get_support()])]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    predictions = nb.predict(X_test)\n",
    "    results.append(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7557281553398059,\n",
       " 0.7529320388349514,\n",
       " 0.7514563106796116,\n",
       " 0.747495145631068,\n",
       " 0.7403495145631068]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:19<00:00, 27.81s/it]\n"
     ]
    }
   ],
   "source": [
    "#getting smaller values\n",
    "results_2 = []\n",
    "for i in tqdm([2, 4, 6, 8, 10]):\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=i)\n",
    "    chis = fs.fit_transform(tfidf, y)\n",
    "    X = df_tf[list(df_tf.columns[fs.get_support()])]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    predictions = nb.predict(X_test)\n",
    "    results_2.append(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7499805825242718,\n",
       " 0.7631844660194175,\n",
       " 0.7685436893203883,\n",
       " 0.7666796116504855,\n",
       " 0.7626407766990291]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percentage of features to use (with Bernoulli), for graphics\n",
    "feat = pd.DataFrame()\n",
    "feat['percentage'] = [2, 4, 6, 8, 10] + list(range(15, 40, 5))\n",
    "feat['accuracy_score'] = results_2 + results\n",
    "feat['number_of_features'] = [45362 * (x/100) for x in [2, 4, 6, 8, 10] + list(range(15, 40, 5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_tester(X_train, X_test, y_train, y_test, model, **kwargs):\n",
    "    \"\"\"Prints basic classification matrix and accuracy for a given model\"\"\"\n",
    "    modeled = model(**kwargs)\n",
    "    modeled.fit(X_train, y_train)\n",
    "    predictions = modeled.predict(X_test)\n",
    "    print(pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True), '\\n')\n",
    "    print('Overall Accuracy', accuracy_score(y_test, predictions))\n",
    "    try:\n",
    "        print('Recall: ', pd.crosstab(y_test, predictions).iloc[1, 1] / \n",
    "              (pd.crosstab(y_test, predictions).iloc[1, 1] + pd.crosstab(y_test, predictions).iloc[1, 0]))\n",
    "        print('Precision: ', pd.crosstab(y_test, predictions).iloc[1, 1] / \n",
    "                     (pd.crosstab(y_test, predictions).iloc[1, 1] + pd.crosstab(y_test, predictions).iloc[0, 1]))\n",
    "    except IndexError:\n",
    "        print('Precision: ', pd.crosstab(y_test, predictions).iloc[1, 0] / \n",
    "             (pd.crosstab(y_test, predictions).iloc[1, 0] + pd.crosstab(y_test, predictions).iloc[0, 0]))\n",
    "        print('Recall: ', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=6, score_func=<function chi2 at 0x10bf9a6a8>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=6)\n",
    "fs.fit(tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_6 = df_tf[list(df_tf.columns[fs.get_support()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_6, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1      1    All\n",
      "Actual                      \n",
      "-1         740   2786   3526\n",
      "1          203   9146   9349\n",
      "All        943  11932  12875 \n",
      "\n",
      "Overall Accuracy 0.7678446601941747\n",
      "Recall:  0.9782864477484223\n",
      "Precision:  0.7665102246061012\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  -1      1    All\n",
      "Actual                     \n",
      "-1         11   3515   3526\n",
      "1          13   9336   9349\n",
      "All        24  12851  12875 \n",
      "\n",
      "Overall Accuracy 0.7259805825242719\n",
      "Recall:  0.9986094769494064\n",
      "Precision:  0.7264804295385573\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    -1      1    All\n",
      "Actual                       \n",
      "-1          720   2806   3526\n",
      "1           776   8573   9349\n",
      "All        1496  11379  12875 \n",
      "\n",
      "Overall Accuracy 0.7217864077669903\n",
      "Recall:  0.9169964702107177\n",
      "Precision:  0.7534053959047368\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  -1      1    All\n",
      "Actual                     \n",
      "-1         28   3498   3526\n",
      "1          45   9304   9349\n",
      "All        73  12802  12875 \n",
      "\n",
      "Overall Accuracy 0.7248155339805825\n",
      "Recall:  0.9951866509787143\n",
      "Precision:  0.7267614435244493\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   -1      1    All\n",
      "Actual                      \n",
      "-1         329   3197   3526\n",
      "1          314   9035   9349\n",
      "All        643  12232  12875 \n",
      "\n",
      "Overall Accuracy 0.7273009708737864\n",
      "Recall:  0.9664135201625842\n",
      "Precision:  0.7386363636363636\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  -1      1    All\n",
      "Actual                     \n",
      "-1         12   3514   3526\n",
      "1          12   9337   9349\n",
      "All        24  12851  12875 \n",
      "\n",
      "Overall Accuracy 0.726135922330097\n",
      "Recall:  0.9987164402609905\n",
      "Precision:  0.7265582444945918\n"
     ]
    }
   ],
   "source": [
    "model_tester(X_train, X_test, y_train, y_test, SVC, kernel='linear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
